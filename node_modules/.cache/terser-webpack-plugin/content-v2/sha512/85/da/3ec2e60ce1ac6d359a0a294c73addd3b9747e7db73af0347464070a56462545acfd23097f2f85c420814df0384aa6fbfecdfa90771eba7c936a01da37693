{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[16],{402:function(t,a,s){\"use strict\";s.r(a);var n=s(54),r=Object(n.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":t.$parent.slotKey}},[s(\"h3\",{attrs:{id:\"pytorch一个基于python的科学计算包\"}},[s(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#pytorch一个基于python的科学计算包\"}},[t._v(\"#\")]),t._v(\" \"),s(\"strong\",[t._v(\"Pytorch一个基于python的科学计算包\")])]),t._v(\" \"),s(\"p\",[t._v(\"服务场合：\")]),t._v(\" \"),s(\"p\",[t._v(\"1.替代numpy发挥GPU性能\")]),t._v(\" \"),s(\"p\",[t._v(\"2.提供了高度灵活性和效率的深度学习实验性平台\")]),t._v(\" \"),s(\"h4\",{attrs:{id:\"tensors\"}},[s(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#tensors\"}},[t._v(\"#\")]),t._v(\" Tensors\")]),t._v(\" \"),s(\"p\",[t._v(\"tensor表示张量，是一种类似于array和matrices的数据结构。pytorch一般用tensors表示输入和输出，同时也表示模型参数。\")]),t._v(\" \"),s(\"h5\",{attrs:{id:\"_1-初始化矩阵\"}},[s(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_1-初始化矩阵\"}},[t._v(\"#\")]),t._v(\" \"),s(\"strong\",[t._v(\"1.初始化矩阵\")])]),t._v(\" \"),s(\"div\",{staticClass:\"language-python extra-class\"},[s(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[s(\"code\",[s(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"from\")]),t._v(\" __future__ \"),s(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"import\")]),t._v(\" print_function\\n\"),s(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"import\")]),t._v(\" torch\\nx \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" torch\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"Tensor\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"5\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"3\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"  \"),s(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# 构造一个未初始化的5*3的矩阵\")]),t._v(\"\\nx \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" torch\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"rand\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"5\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"3\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"  \"),s(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# 构造一个随机初始化的矩阵\")]),t._v(\"\\ny \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" torch\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"rand\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"5\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"3\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n\")])])]),s(\"h5\",{attrs:{id:\"_2-将两种同类型矩阵相加\"}},[s(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_2-将两种同类型矩阵相加\"}},[t._v(\"#\")]),t._v(\" 2.将两种同类型矩阵相加\")]),t._v(\" \"),s(\"div\",{staticClass:\"language-python extra-class\"},[s(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[s(\"code\",[s(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"#此处 将两个同形矩阵相加有两种语法结构\")]),t._v(\"\\nx \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),t._v(\" y \"),s(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# 语法一\")]),t._v(\"\\ntorch\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"add\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"x\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" y\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),s(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# 语法二\")]),t._v(\"\\n\\n\")])])]),s(\"h5\",{attrs:{id:\"_3-输出矩阵\"}},[s(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_3-输出矩阵\"}},[t._v(\"#\")]),t._v(\" 3.输出矩阵\")]),t._v(\" \"),s(\"div\",{staticClass:\"language-python extra-class\"},[s(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[s(\"code\",[t._v(\"result \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" torch\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"Tensor\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"5\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"3\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),s(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# 语法一\")]),t._v(\"\\ntorch\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"add\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"x\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" y\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" out\"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\"result\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),s(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# 语法二\")]),t._v(\"\\ny\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"add_\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"x\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),s(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# 将y与x相加\")]),t._v(\"\\n\")])])]),s(\"p\",[t._v(\"tip：任何可以改变tensor内容的操作都会在方法后加一个_\")]),t._v(\" \"),s(\"h5\",{attrs:{id:\"_4-切片操作\"}},[s(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_4-切片操作\"}},[t._v(\"#\")]),t._v(\" 4.切片操作\")]),t._v(\" \"),s(\"div\",{staticClass:\"language-python extra-class\"},[s(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[s(\"code\",[t._v(\"x\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\":\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" \"),s(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"#这一操作会输出x矩阵的第二列的所有值\")]),t._v(\"\\n\")])])]),s(\"h4\",{attrs:{id:\"numpy桥\"}},[s(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#numpy桥\"}},[t._v(\"#\")]),t._v(\" Numpy桥\")]),t._v(\" \"),s(\"h5\",{attrs:{id:\"_1-tensor转换为numpy\"}},[s(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_1-tensor转换为numpy\"}},[t._v(\"#\")]),t._v(\" 1.tensor转换为numpy\")]),t._v(\" \"),s(\"div\",{staticClass:\"language-python extra-class\"},[s(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[s(\"code\",[t._v(\"a \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" torch\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"ones\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"5\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\nb \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" a\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"numpy\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n\")])])]),s(\"h5\",{attrs:{id:\"_2-修改numpy数组之后-与之相关联的tensor也会相应被修改\"}},[s(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_2-修改numpy数组之后-与之相关联的tensor也会相应被修改\"}},[t._v(\"#\")]),t._v(\" 2.修改numpy数组之后，与之相关联的tensor也会相应被修改\")]),t._v(\" \"),s(\"div\",{staticClass:\"language- extra-class\"},[s(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[s(\"code\",[t._v(\"a.add_(1)\\nprint(a)\\nprint(b)\\n\")])])]),s(\"h5\",{attrs:{id:\"_3-将numpy的array转换为tensor\"}},[s(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_3-将numpy的array转换为tensor\"}},[t._v(\"#\")]),t._v(\" 3.将numpy的array转换为tensor\")]),t._v(\" \"),s(\"p\",[t._v(\"修改numpy也会相应修改关联的tensor\")]),t._v(\" \"),s(\"div\",{staticClass:\"language-python extra-class\"},[s(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[s(\"code\",[s(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"import\")]),t._v(\" numpy \"),s(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"as\")]),t._v(\" np\\na \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" np\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"ones\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"5\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\nb \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" torch\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"from_numpy\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"a\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\nnp\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"add\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"a\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" out\"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\"a\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n\"),s(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"print\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"a\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n\"),s(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"print\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"b\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n\")])])]),s(\"h5\",{attrs:{id:\"_4-当cuda可用会进行gpu运算\"}},[s(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_4-当cuda可用会进行gpu运算\"}},[t._v(\"#\")]),t._v(\" 4.当cuda可用会进行GPU运算\")]),t._v(\" \"),s(\"div\",{staticClass:\"language-python extra-class\"},[s(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[s(\"code\",[s(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" torch\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"cuda\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"is_available\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\":\")]),t._v(\"\\n    x \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" x\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"cuda\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n    y \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" y\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"cuda\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n    x \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),t._v(\" y\\n\")])])]),s(\"h3\",{attrs:{id:\"pytorch中的神经网络\"}},[s(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#pytorch中的神经网络\"}},[t._v(\"#\")]),t._v(\" Pytorch中的神经网络\")]),t._v(\" \"),s(\"p\",[t._v(\"pytorch中所有神经网络都来自于autograd包\")]),t._v(\" \"),s(\"h5\",{attrs:{id:\"_1-autograd-自动求导\"}},[s(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_1-autograd-自动求导\"}},[t._v(\"#\")]),t._v(\" 1.autograd：自动求导\")]),t._v(\" \"),s(\"p\",[t._v(\"autograd包提供tensor所有操作的自动求导方法。\")]),t._v(\" \"),s(\"p\",[t._v(\"autograd.Variable是包中最核心的类。包装一个tensor并几乎支持所有定义在其上的操作（除了部分会修改tensor自身的inplace函数）。完成运算可以调用.backward()自动计算所有梯度。\")]),t._v(\" \"),s(\"p\",[t._v(\"属性.data：访问原始tensor\")]),t._v(\" \"),s(\"p\",[t._v(\"属性.grad：variable的所有梯度\")]),t._v(\" \"),s(\"p\",[t._v(\"属性.creator：引用一个创建Variable的Function\")]),t._v(\" \"),s(\"p\",[t._v(\"example:手动和自动计算\"),s(\"em\",[t._v(\"y\")]),t._v(\"=\"),s(\"em\",[t._v(\"2x\")]),t._v(\"∙\"),s(\"em\",[t._v(\"e**x\")]),t._v(\"+\"),s(\"em\",[t._v(\"x\")]),t._v(\"2∙\"),s(\"em\",[t._v(\"e**x\")]),t._v(\"导数\")]),t._v(\" \"),s(\"div\",{staticClass:\"language-python extra-class\"},[s(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[s(\"code\",[s(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"def\")]),t._v(\" \"),s(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"f\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"x\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\":\")]),t._v(\"\\n    \"),s(\"span\",{pre:!0,attrs:{class:\"token triple-quoted-string string\"}},[t._v(\"'''计算y'''\")]),t._v(\"\\n    y \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" x\"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"**\")]),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"2\")]),t._v(\" \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"*\")]),t._v(\" t\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"exp\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"x\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n    \"),s(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" y\\n\\n\"),s(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"def\")]),t._v(\" \"),s(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"gradf\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"x\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\":\")]),t._v(\"\\n    \"),s(\"span\",{pre:!0,attrs:{class:\"token triple-quoted-string string\"}},[t._v(\"'''手动求导函数'''\")]),t._v(\"\\n    dx \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"2\")]),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"*\")]),t._v(\"x\"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"*\")]),t._v(\"t\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"exp\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"x\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),t._v(\" x\"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"**\")]),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"2\")]),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"*\")]),t._v(\"t\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"exp\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"x\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n    \"),s(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" dx\\n\\n\\n\")])])]),s(\"div\",{staticClass:\"language-python extra-class\"},[s(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[s(\"code\",[t._v(\"x \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" t\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"randn\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"3\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"4\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" requires_grad \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),s(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[t._v(\"True\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\ny \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" f\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"x\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\ny\\n\")])])]),s(\"p\",[t._v(\"tensor([[ 0.0928,  0.1978,  0.6754,  0.8037],\\n[ 0.9882,  0.3546,  0.2380,  0.0002],\\n[ 0.2863,  0.0448,  0.1516,  2.9122]])\")]),t._v(\" \"),s(\"div\",{staticClass:\"language-python extra-class\"},[s(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[s(\"code\",[t._v(\"y\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"backward\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"t\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"ones\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"y\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"size\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),s(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# gradient形状与y一致\")]),t._v(\"\\nx\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"grad\\n\")])])]),s(\"p\",[t._v(\"tensor([[-0.4146, -0.4610,  2.9016,  3.2831],\\n[ 3.8102,  1.8614, -0.4536, -0.0244],\\n[-0.4321,  0.5110, -0.4549,  8.6048]])\")]),t._v(\" \"),s(\"div\",{staticClass:\"language-python extra-class\"},[s(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[s(\"code\",[s(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# autograd的计算结果与利用公式手动计算的结果一致\")]),t._v(\"\\ngradf\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"x\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \\n\")])])]),s(\"p\",[t._v(\"tensor([[-0.4146, -0.4610,  2.9016,  3.2831],\\n[ 3.8102,  1.8614, -0.4536, -0.0244],\\n[-0.4321,  0.5110, -0.4549,  8.6048]])\")]),t._v(\" \"),s(\"hr\"),t._v(\" \"),s(\"div\",{staticClass:\"language-python extra-class\"},[s(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[s(\"code\",[t._v(\"x \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" t\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"ones\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\nb \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" t\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"rand\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" requires_grad \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),s(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[t._v(\"True\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\nw \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" t\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"rand\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" requires_grad \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),s(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[t._v(\"True\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\ny \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" w \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"*\")]),t._v(\" x \"),s(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# 等价于y=w.mul(x)\")]),t._v(\"\\nz \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" y \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),t._v(\" b \"),s(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# 等价于z=y.add(b)\")]),t._v(\"\\n\")])])]),s(\"p\",[t._v(\"在PyTorch实现中，autograd会随着用户的操作，记录生成当前variable的所有操作，并由此建立一个有向无环图。用户每进行一个操作，相应的计算图就会发生改变。更底层的实现中，图中记录了操作Function，每一个变量在图中的位置可通过其grad_fn属性在图中的位置推测得到。在反向传播过程中**，autograd沿着这个图从当前变量（根节点z ）溯源，可以利用链式求导法则计算所有叶子节点的梯度**。每一个前向传播操作的函数都有与之对应的反向传播函数用来计算输入的各个variable的梯度，这些函数的函数名通常以Backward结尾。\")]),t._v(\" \"),s(\"div\",{staticClass:\"language-python extra-class\"},[s(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[s(\"code\",[t._v(\"x\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"requires_grad\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" b\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"requires_grad\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" w\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"requires_grad\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" y\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"requires_grad\\n\")])])]),s(\"p\",[t._v(\"False   True   True   True\")]),t._v(\" \"),s(\"p\",[t._v(\"变量的\"),s(\"code\",[t._v(\"requires_grad\")]),s(\"strong\",[t._v(\"属性默认为False\")]),t._v(\"，如果某一个节点requires_grad被设置为True，那么\"),s(\"strong\",[t._v(\"所有依赖它的节点\"),s(\"code\",[t._v(\"requires_grad\")]),t._v(\"都是True\")]),t._v(\"。\")]),t._v(\" \"),s(\"div\",{staticClass:\"language-python extra-class\"},[s(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[s(\"code\",[s(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# 使用retain_graph来保存buffer\")]),t._v(\"\\nz\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"backward\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"retain_graph\"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),s(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[t._v(\"True\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\nw\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"grad\\n\")])])]),s(\"p\",[t._v(\"计算w的梯度的时候，需要用到x的数值，这些数值在前向过程中会保存成buffer，在计算完梯度之后会自动清空。为了能够多次反向传播需要指定\"),s(\"code\",[t._v(\"retain_graph\")]),t._v(\"来保留这些buffer。\")]),t._v(\" \"),s(\"div\",{staticClass:\"language-python extra-class\"},[s(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[s(\"code\",[t._v(\"a \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" t\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"ones\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"3\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"4\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"requires_grad\"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),s(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[t._v(\"True\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\nb \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" t\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"ones\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"3\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"4\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"requires_grad\"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),s(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[t._v(\"True\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\nc \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" a \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"*\")]),t._v(\" b\\n\\na\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"data \"),s(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# 还是一个tensor\")]),t._v(\"\\n\")])])]),s(\"p\",[t._v(\"tensor([[ 1.,  1.,  1.,  1.],\\n[ 1.,  1.,  1.,  1.],\\n[ 1.,  1.,  1.,  1.]])\")]),t._v(\" \"),s(\"div\",{staticClass:\"language-python extra-class\"},[s(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[s(\"code\",[t._v(\"d \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" a\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"data\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"sigmoid_\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \\n\"),s(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# sigmoid_ 是个inplace操作，会修改a自身的值\")]),t._v(\"\\na\\n\")])])]),s(\"p\",[t._v(\"tensor([[ 0.7311,  0.7311,  0.7311,  0.7311],\\n[ 0.7311,  0.7311,  0.7311,  0.7311],\\n[ 0.7311,  0.7311,  0.7311,  0.7311]])\")]),t._v(\" \"),s(\"p\",[t._v(\"如果我们想要修改tensor的数值，但是又不希望被autograd记录，那么我么可以\"),s(\"strong\",[t._v(\"对tensor.data进行操作\")])]),t._v(\" \"),s(\"hr\"),t._v(\" \"),s(\"div\",{staticClass:\"language-python extra-class\"},[s(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[s(\"code\",[s(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"from\")]),t._v(\" torch\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"autograd \"),s(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"import\")]),t._v(\" Variable\\nx \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" Variable\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"torch\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"ones\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"2\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"2\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" requires_grad \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),s(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[t._v(\"True\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\ny \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" x \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),t._v(\" \"),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"2\")]),t._v(\"\\ny\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"creator\\n\\n\"),s(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# y 是作为一个操作的结果创建的因此y有一个creator \")]),t._v(\"\\nz \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" y \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"*\")]),t._v(\" y \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"*\")]),t._v(\" \"),s(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"3\")]),t._v(\"\\nout \"),s(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" z\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"mean\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n\\n\"),s(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# 现在我们来使用反向传播\")]),t._v(\"\\nout\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"backward\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n\\n\"),s(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# out.backward()和操作out.backward(torch.Tensor([1.0]))是等价的\")]),t._v(\"\\n\"),s(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# 在此处输出 d(out)/dx\")]),t._v(\"\\nx\"),s(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"grad\\n\")])])]),s(\"p\",[t._v(\"最终得出的结果应该是一个全是4.5的矩阵。设置输出的变量为\"),s(\"strong\",[t._v(\"o\")]),t._v(\"。我们通过这一公式来计算：\")]),t._v(\" \"),s(\"p\",[s(\"img\",{attrs:{src:\"https://www.zhihu.com/equation?tex=o+%3D+%5Cfrac%7B1%7D%7B4%7D%5Csum_i+z_i\",alt:\"[公式]\"}}),t._v(\"，\"),s(\"img\",{attrs:{src:\"https://www.zhihu.com/equation?tex=z_i+%3D+3%28x_i%2B2%29%5E2\",alt:\"[公式]\"}}),t._v(\"，\"),s(\"img\",{attrs:{src:\"https://www.zhihu.com/equation?tex=z_i%5Cbigr%5Crvert_%7Bx_i%3D1%7D+%3D+27\",alt:\"[公式]\"}}),t._v(\"，因此，\"),s(\"img\",{attrs:{src:\"https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+o%7D%7B%5Cpartial+x_i%7D+%3D+%5Cfrac%7B3%7D%7B2%7D%28x_i%2B2%29\",alt:\"[公式]\"}}),t._v(\"，最后有\"),s(\"img\",{attrs:{src:\"https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+o%7D%7B%5Cpartial+x_i%7D%5Cbigr%5Crvert_%7Bx_i%3D1%7D+%3D+%5Cfrac%7B9%7D%7B2%7D+%3D+4.5\",alt:\"[公式]\"}})]),t._v(\" \"),s(\"p\",[t._v(\"如果你想要进行求导计算，你可以在Variable上调用.backward()。 如果Variable是一个标量（例如它包含一个单元素数据），你无需对backward()指定任何参数，然而如果它有更多的元素，你需要指定一个和tensor的形状想匹配的grad_output参数。\")]),t._v(\" \"),s(\"h5\",{attrs:{id:\"_2-神经网络\"}},[s(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_2-神经网络\"}},[t._v(\"#\")]),t._v(\" 2.神经网络\")]),t._v(\" \"),s(\"p\",[t._v(\"使用torch.nn可以进行神经网络构建。\")]),t._v(\" \"),s(\"p\",[t._v(\"nn.Module包含神经网络的层，forward（input）方法能将output返回。\")]),t._v(\" \"),s(\"p\",[s(\"img\",{attrs:{src:\"6.assets/v2-06a914f4ee93f25c0d6c924df9b4b4cb_r.jpg\",alt:\"preview\"}})]),t._v(\" \"),s(\"p\",[t._v(\"典型的神经网络训练过程：\")]),t._v(\" \"),s(\"ul\",[s(\"li\",[t._v(\"定义一个有着可学习的参数（或者权重）的神经网络\")]),t._v(\" \"),s(\"li\",[t._v(\"对着一个输入的数据集进行迭代:\\n\"),s(\"ul\",[s(\"li\",[t._v(\"用神经网络对输入进行处理\")]),t._v(\" \"),s(\"li\",[t._v(\"计算代价值（对输入的修正）\")]),t._v(\" \"),s(\"li\",[t._v(\"将梯度传播回神经网络参数中\")]),t._v(\" \"),s(\"li\",[t._v(\"更新网络中的权重\")])])])])])}),[],!1,null,null,null);a.default=r.exports}}]);","extractedComments":[]}